# -*- coding: utf-8 -*-
"""Code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ti1vxWp2RX6kCgC5Ll6RTj09Ie9mjcgn
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

plt.style.use("seaborn-v0_8")
sns.set_palette("deep")

df = pd.read_csv("/content/drive/MyDrive/Dataset/employee_salary_dataset.csv")
df.head()

df.info()
df.describe(include="all")
print("Valeurs manquantes :\n", df.isna().sum())
print("Doublons :", df.duplicated().sum())

gender_counts = df["Gender"].value_counts()
display(gender_counts)

plt.figure(figsize=(5,5))
gender_counts.plot(kind="bar")
plt.title("Répartition par genre")
plt.xlabel("Genre")
plt.ylabel("Nombre")
plt.show()

print(df["Department"].unique())
dept_counts = df["Department"].value_counts()
display(dept_counts)

plt.figure(figsize=(10,5))
sns.countplot(data=df, x="Department")
plt.xticks(rotation=45)
plt.title("Répartition des employés par département")
plt.show()

plt.figure(figsize=(7,5))
sns.histplot(df["Monthly_Salary"], kde=True)
plt.title("Distribution des salaires")
plt.show()

plt.figure(figsize=(7,5))
sns.boxplot(data=df, x="Gender", y="Monthly_Salary")
plt.title("Salaire selon le genre")
plt.show()

plt.figure(figsize=(10,5))
sns.boxplot(data=df, x="Department", y="Monthly_Salary")
plt.xticks(rotation=45)
plt.title("Salaire par département")
plt.show()

Experience_Years = df.pivot_table(
    index="Experience_Years",
    values="Monthly_Salary",
    aggfunc=["max","mean","min"]
)
display(Experience_Years)

plt.figure(figsize=(8,5))
sns.lineplot(data=Experience_Years["mean"])
plt.title("Salaire moyen selon les années d'expérience")
plt.ylabel("Salaire moyen")
plt.xlabel("Années d'expérience")
plt.show()

plt.figure(figsize=(10,6))
sns.heatmap(df.corr(numeric_only=True), annot=True, cmap="coolwarm")
plt.title("Matrice de corrélation")
plt.show()

sns.pairplot(df, diag_kind="kde")
plt.show()

from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split

le = LabelEncoder()
for col in df.select_dtypes(include="object"):
    df[col] = le.fit_transform(df[col])

X = df.drop("Monthly_Salary", axis=1)
y = df["Monthly_Salary"]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, ExtraTreesRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error, r2_score

models = {
    "Linear Regression": LinearRegression(),
    "Ridge": Ridge(),
    "Lasso": Lasso(),
    "KNN": KNeighborsRegressor(),
    "Decision Tree": DecisionTreeRegressor(),
    "Random Forest": RandomForestRegressor(),
    "Extra Trees": ExtraTreesRegressor(),
    "Gradient Boosting": GradientBoostingRegressor(),
    "AdaBoost": AdaBoostRegressor(),
    "XGBoost": XGBRegressor(objective='reg:squarederror')
}

results = []

for name, model in models.items():
    model.fit(X_train, y_train)
    pred = model.predict(X_test)
    mse = mean_squared_error(y_test, pred)
    r2 = r2_score(y_test, pred)

    results.append([name, mse, r2])

results_df = pd.DataFrame(results, columns=["Model", "MSE", "R2 Score"])
display(results_df)

from sklearn.model_selection import KFold, cross_val_score

kfold = KFold(n_splits=10, shuffle=True, random_state=42)

for name, model in models.items():
    scores = cross_val_score(model, X, y, cv=kfold, scoring='r2')
    print(f"{name} → Mean R2: {scores.mean():.4f} | Std: {scores.std():.4f}")

from sklearn.model_selection import StratifiedKFold
import numpy as np

y_bins = pd.qcut(y, q=5, labels=False)
skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)

for name, model in models.items():
    scores = []
    for train_idx, test_idx in skf.split(X, y_bins):
        model.fit(X.iloc[train_idx], y.iloc[train_idx])
        pred = model.predict(X.iloc[test_idx])
        scores.append(r2_score(y.iloc[test_idx], pred))
    print(f"{name} → Stratified Mean R2: {np.mean(scores):.4f}")